{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Breast cancer data used. What's most important is that **if train data was preprocessed for model fitting, test data should be also preprocessed for prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.utils.Bunch,\n",
       " {'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "          1.189e-01],\n",
       "         [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "          8.902e-02],\n",
       "         [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "          8.758e-02],\n",
       "         ...,\n",
       "         [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "          7.820e-02],\n",
       "         [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "          1.240e-01],\n",
       "         [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "          7.039e-02]]),\n",
       "  'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "         0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "         1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "         1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "         0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "         1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  'frame': None,\n",
       "  'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       "  'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       "  'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "         'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "         'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "         'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "         'smoothness error', 'compactness error', 'concavity error',\n",
       "         'concave points error', 'symmetry error',\n",
       "         'fractal dimension error', 'worst radius', 'worst texture',\n",
       "         'worst perimeter', 'worst area', 'worst smoothness',\n",
       "         'worst compactness', 'worst concavity', 'worst concave points',\n",
       "         'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       "  'filename': 'C:\\\\Users\\\\sori-\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "bc = load_breast_cancer()\n",
    "type(bc), bc                   # Bunch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set x, y\n",
    "x = bc.data\n",
    "y = bc.target\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plotting to visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "**Splitting data should be done after standardization on the job** which is the next step. Here, it is done before to see what happens when test data is not standardized for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 30), (86,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.85, random_state=5)\n",
    "x_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization - Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler object\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.47622369, -0.13203122,  1.41763676, ...,  1.47582537,\n",
       "         1.01857964, -0.05243044],\n",
       "       [-1.69515898,  0.36557803, -1.61299365, ..., -0.53111345,\n",
       "         0.67375681,  3.54873819],\n",
       "       [-0.08191173,  1.07811709, -0.00641967, ...,  1.35569551,\n",
       "         2.4540049 ,  1.35491021],\n",
       "       ...,\n",
       "       [ 1.10111701,  0.44033623,  1.3714829 , ...,  1.28022931,\n",
       "         0.55026212,  1.96918204],\n",
       "       [ 0.48651915,  0.88187682,  0.58686725, ...,  1.38803816,\n",
       "         0.59677311,  2.26534882],\n",
       "       [-1.21704224, -0.43573639, -1.2080984 , ..., -0.88395642,\n",
       "         0.13968238, -0.55372014]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit & transform \"x_train\" data - can be done at once by fit_transform()\n",
    "scaler.fit(x_train)                            # Get mean & standard deviation of each column\n",
    "x_train_t = scaler.transform(x_train)          # Perform standardization\n",
    "x_train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Target value is 'malignant' or benign'. It has **binary class** of the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logi = LogisticRegression(solver='newton-cg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the score changes, I will try several different cases with untransformed and transformed data. <br>\n",
    "#### 1) Fit with untransformed train data & Predict untransfored train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]),\n",
       " array([[ 0.87760113,  0.19311463, -0.32945302,  0.0257606 , -0.16369568,\n",
       "         -0.20656024, -0.49908735, -0.26724573, -0.25612174, -0.02831329,\n",
       "         -0.04762646,  1.45630108,  0.10908966, -0.10390196, -0.02647736,\n",
       "          0.05851127, -0.03716508, -0.03287373, -0.04078685,  0.01323775,\n",
       "         -0.00178078, -0.45176192, -0.10898359, -0.0107303 , -0.34384812,\n",
       "         -0.57879696, -1.2895823 , -0.52895258, -0.74231851, -0.09037023]]),\n",
       " array([33.09588923]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model \n",
    "logi.fit(x_train, y_train)\n",
    "logi.classes_, logi.coef_, logi.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category\n",
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data\n",
    "pd.DataFrame(logi.predict(x_train), columns=['Category']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category\n",
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with actual data\n",
    "pd.DataFrame(y_train, columns=['Category']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score - Mean accuracy\n",
    "logi.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       179\n",
      "           1       0.96      0.97      0.97       304\n",
      "\n",
      "    accuracy                           0.96       483\n",
      "   macro avg       0.95      0.95      0.95       483\n",
      "weighted avg       0.96      0.96      0.96       483\n",
      "\n",
      "Matrix:  [[167  12]\n",
      " [  9 295]]\n",
      "R-squared:  0.813602616877389\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score\n",
    "\n",
    "# 1. Classification report\n",
    "cr = classification_report(y_train, logi.predict(x_train))\n",
    "print('Report: ', cr)\n",
    "\n",
    "# 2. Confusion_matrix\n",
    "cm = confusion_matrix(y_train, logi.predict(x_train))\n",
    "print('Matrix: ', cm)\n",
    "\n",
    "# 3. R2\n",
    "r2 = r2_score(y_train, logi.predict(x_train))\n",
    "print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Fit with transformed train data & Predict transfored train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "logi.fit(x_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data\n",
    "pd.DataFrame(logi.predict(x_train_t)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917184265010351"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score\n",
    "logi.score(x_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       179\n",
      "           1       0.99      1.00      0.99       304\n",
      "\n",
      "    accuracy                           0.99       483\n",
      "   macro avg       0.99      0.99      0.99       483\n",
      "weighted avg       0.99      0.99      0.99       483\n",
      "\n",
      "Matrix:  [[176   3]\n",
      " [  1 303]]\n",
      "R-squared:  0.9644957365480741\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# 1. Classification report\n",
    "cr = classification_report(y_train, logi.predict(x_train_t))\n",
    "print('Report: ', cr)\n",
    "\n",
    "# 2. Confusion_matrix\n",
    "cm = confusion_matrix(y_train, logi.predict(x_train_t))\n",
    "print('Matrix: ', cm)\n",
    "\n",
    "# 3. R2\n",
    "r2 = r2_score(y_train, logi.predict(x_train_t))\n",
    "print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The outcome of 1) with untransfored data was big enough, but the score with transformed data got much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Fit with transformed train data & Predict untransfored test data\n",
    "This could happend often on the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "logi.fit(x_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data\n",
    "logi.predict(x_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with actual data\n",
    "y_test[:5]             # Big difference from prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38372093023255816"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score\n",
    "logi.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55        33\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.38        86\n",
      "   macro avg       0.19      0.50      0.28        86\n",
      "weighted avg       0.15      0.38      0.21        86\n",
      "\n",
      "Matrix:  [[33  0]\n",
      " [53  0]]\n",
      "R-squared:  -1.606060606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sori-\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sori-\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sori-\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# 1. Classification report\n",
    "cr = classification_report(y_test, logi.predict(x_test))\n",
    "print('Report: ', cr)\n",
    "\n",
    "# 2. Confusion_matrix\n",
    "cm = confusion_matrix(y_test, logi.predict(x_test))\n",
    "print('Matrix: ', cm)\n",
    "\n",
    "# 3. R2\n",
    "r2 = r2_score(y_test, logi.predict(x_test))\n",
    "print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R-squared is very low compared to the previous outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Fit with transformed train data & Predict transfored test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.58472063e-01,  1.19228003e+00,  3.38213328e-01, ...,\n",
       "         1.16005338e+00,  1.92975390e+00,  8.57441644e-01],\n",
       "       [-5.18210324e-01,  4.81017431e-01, -5.09856374e-01, ...,\n",
       "        -5.79790727e-01, -1.06698772e+00,  3.89022798e-01],\n",
       "       [ 4.85579046e-02, -2.16114822e+00,  3.28330187e-02, ...,\n",
       "         2.53598088e-04, -9.01356108e-03, -2.45761431e-01],\n",
       "       ...,\n",
       "       [ 4.84129784e-01,  3.22440852e-01,  4.81125296e-01, ...,\n",
       "         1.31687945e-01,  9.97850736e-01, -4.74071373e-01],\n",
       "       [-1.58732327e-01,  1.56868247e-01, -1.20609304e-01, ...,\n",
       "         4.84105313e-01,  5.14010702e-01,  1.82141695e+00],\n",
       "       [-5.41825667e-01, -5.17082214e-01, -5.69277666e-01, ...,\n",
       "        -5.77335360e-01,  3.72606748e-01, -1.71427962e-01]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get transformed x_test data\n",
    "scaler = StandardScaler()\n",
    "x_test_t = scaler.fit_transform(x_test)\n",
    "x_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "logi.fit(x_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data\n",
    "logi.predict(x_test_t)[:5]        # Looks better than untransformated test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651162790697675"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score\n",
    "logi.score(x_test_t, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        33\n",
      "           1       0.95      1.00      0.97        53\n",
      "\n",
      "    accuracy                           0.97        86\n",
      "   macro avg       0.97      0.95      0.96        86\n",
      "weighted avg       0.97      0.97      0.96        86\n",
      "\n",
      "Matrix:  [[30  3]\n",
      " [ 0 53]]\n",
      "R-squared:  0.8524871355060034\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# 1. Classification report\n",
    "cr = classification_report(y_test, logi.predict(x_test_t))\n",
    "print('Report: ', cr)\n",
    "\n",
    "# 2. Confusion_matrix\n",
    "cm = confusion_matrix(y_test, logi.predict(x_test_t))\n",
    "print('Matrix: ', cm)\n",
    "\n",
    "# 3. R2\n",
    "r2 = r2_score(y_test, logi.predict(x_test_t))\n",
    "print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R-squared got much better. Thus, **using transformated data for both fitting & prediction steps enables more accuarate prediction.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
